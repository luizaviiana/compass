# üöÄ Desafio 

## üìå Resumo

Nesse desafio, dei continuidade √† quarta etapa do projeto final, dedicada √† constru√ß√£o da camada Refined do Data Lake. Ap√≥s a ingest√£o dos dados brutos do CSV e da API TMDB e seu processamento na camada Trusted na sprint anterior, iniciei esta etapa com a defini√ß√£o e valida√ß√£o do modelo dimensional, estruturado para responder √†s perguntas anal√≠ticas sobre representatividade feminina em filmes de guerra a partir de 1950.

O modelo foi composto por dimens√µes como dimArtista, dimDiretor e dimTempo, al√©m de tabelas ponte filmeDiretor e filmeArtista e da tabela fato fatoRepresentacaoFeminina. Cada dimens√£o foi criada com base nos dados j√° tratados na Trusted, e os relacionamentos foram estabelecidos a partir de chaves. A modelagem foi implementada com jobs no AWS Glue Studio, onde apliquei transforma√ß√µes com PySpark para consolidar os dados, remover duplica√ß√µes e garantir joins corretos apenas entre filmes que estavam presentes tanto no CSV quanto na API TMDB. Os dados resultantes foram gravados em formato Parquet, com estrutura de diret√≥rios definida no S3. Em seguida, utilizei crawlers para catalogar as novas tabelas da camada Refined no Glue Data Catalog.

Finalizei a sprint com testes e consultas no Athena, validando a integridade dos relacionamentos, as quantidades de registros e os filtros esperados, essa etapa foi essencial para tornar os dados prontos para an√°lise.


## üóÇÔ∏è Sum√°rio 

1. [Etapa 4](#etapa-4)
    - 1.1 [Modelagem Dimensional](#11-modelagem-dimensional)
    - 1.2 [Dimens√£o Tempo](#12-dimens√£o-tempo)
    - 1.3 [Dimens√£o Pa√≠s](#13-dimens√£o-pa√≠s)
    - 1.4 [Dimens√£o Diretor](#14-dimens√£o-diretor)
    - 1.5 [Dimens√£o Artista](#15-dimens√£o-artista)
    - 1.6 [Ponte Filme Artista](#16-ponte-filme-artista)
    - 1.7 [Ponte Filme Diretor](#17-ponte-filme-diretor)
    - 1.8 [Fato Representa√ß√£o Feminina](#18-fato-representa√ß√£o-feminina)



<br>

---

# Etapa 4

A seguir estarei detalhando um pouco mais dos scripts utilizados em cada fase, de como foi a execu√ß√£o e as evid√™ncias de cada a√ß√£o tomada:

| Arquivo | Link |
|--------|------|
| job_dim_tempo | [üîó job_dim_tempo ](./job_dim_tempo.py) |
| job_dim_pais | [üîó job_dim_pais ](./job_dim_pais.py) |
| job_dim_diretor | [üîó job_dim_diretor ](./job_dim_diretor.py) |
| job_dim_artista | [üîó job_dim_artista ](./job_dim_artista.py) |
| job_filme_artista | [üîó job_filme_artista ](./job_filme_artista.py) |
| job_filme_diretor | [üîó job_filme_diretor ](./job_filme_diretor.py) |
| job_fato_rep_feminina | [üîó job_fato_rep_feminina ](./job_fato_rep_feminina.py) |

<br>


## 1.1 Modelagem Dimensional



A etapa teve in√≠cio com o planejamento da modelagem dimensional da camada Refined, com base nas perguntas anal√≠ticas definidas anteriormente, que investigam a representatividade feminina em filmes de guerra desde 1950. A modelagem foi pensada para permitir an√°lises eficientes sobre personagens femininas, diretores, pa√≠ses, notas, popularidade e evolu√ß√£o temporal dos filmes.

Comecei identificando os principais eixos de an√°lise, o que me levou √† defini√ß√£o de uma tabela fato e quatro dimens√µes e duas pontes. A estrutura foi desenhada seguindo boas pr√°ticas de modelagem star schema, utilizando chaves substitutas para garantir integridade referencial entre as tabelas e facilitar o relacionamento entre os dados.

As tabelas criadas foram:

- **dimTempo**: dimens√£o temporal criada a partir dos anos de lan√ßamento dos filmes presentes na tabela csv_movies. Inclui as colunas id_tempo, ano e decada, permitindo an√°lises hist√≥ricas e agrupamentos por per√≠odo. Essa tabela √© essencial para analisar a evolu√ß√£o da representatividade feminina ao longo das d√©cadas.

- **dimPais**: constru√≠da a partir dos campos origin_country e production_countries da tabela tmdb_movies. Nessa tabela usei a fun√ß√£o explode, gerando uma coluna chamada id_pais com os c√≥digos dos pa√≠ses e , em paralelo,  extrai os nomes dos pa√≠ses. Essa dimens√£o permite avaliar quais pa√≠ses mais produziram filmes com maior representa√ß√£o feminina.

- **dimDiretor**: criada com base na equipe t√©cnica dos filmes, campo credits.crew da API TMDB. Cont√©m as colunas id_diretor, nome_diretor e genero. Como um filme pode ter m√∫ltiplos diretores, foi necess√°rio criar uma tabela ponte, filmeDiretor, para garantir o relacionamento muitos-para-muitos. Essa dimens√£o √© importante para explorar a influ√™ncia da dire√ß√£o na presen√ßa feminina no elenco.

- **dimArtista**: constru√≠da a partir dos dados do elenco extra√≠dos do campo credits.cast da TMDB. Cont√©m id_artista, nome_artista e genero, e √© fundamental para realizar an√°lises relacionadas √† participa√ß√£o feminina nos filmes de guerra. Como a rela√ß√£o entre filmes e artistas √© de muitos-para-muitos, foi criada a tabela ponte filmeArtista.

- **filmeArtista**: tabela de relacionamento entre filmes e artistas, com as colunas id_filme, id_artista, ordem_elenco e papel. As informa√ß√µes foram obtidas da API TMDB, e essa ponte permite identificar o papel representado por cada artista e sua posi√ß√£o no elenco.

- **filmeDiretor**: tabela de relacionamento entre filmes e diretores, com as colunas id_filme e id_diretor, tamb√©m extra√≠da da API TMDB. Garante a correta associa√ß√£o entre m√∫ltiplos diretores e os filmes correspondentes.

- **fatoRepresentacaoFeminina**: a tabela fato central do projeto. Nela, consolidei os filmes que atendem aos crit√©rios de an√°lise (g√™nero "guerra", nota ‚â• 6, votos ‚â• 100, ano ‚â• 1950). Os dados da API TMDB j√° foram extra√≠dos com esses filtros, portanto, ao cruzar com o CSV, apenas os filmes com id presente em ambas as fontes foram mantidos. A tabela cont√©m: id_filme, chave prim√°ria da fato; titulo_principal, do CSV; titulo_original, do TMDB; ano_lancamento, do CSV; id_pais, primeiro pa√≠s listado no campo origin_country da TMDB; nota_media e numero_votos, do CSV; popularidade, do TMDB; id_tempo chave estrangeira para dimTempo; id_diretores, lista agregada com todos os diretores vinculados ao filme, para liga√ß√£o com a dimDiretor.

A constru√ß√£o dessa modelagem foi essencial para garantir uma vis√£o consolidada dos filmes e suas conex√µes com artistas, diretores, tempo e pa√≠s, facilitando a realiza√ß√£o de an√°lises nas camadas posteriores. A estrutura tamb√©m respeita o princ√≠pio da separa√ß√£o de responsabilidades: os fatos num√©ricos e relacionais ficam na tabela fato, enquanto os atributos descritivos permanecem organizados nas dimens√µes, promovendo flexibilidade e desempenho nas consultas anal√≠ticas.

![Evid√™ncia 1](../Evid√™ncias/Evidencia1.png)


## 1.2 Dimens√£o Tempo


**Data Catalog**

Na AWS, iniciei criando o Glue Database com o nome filmes_refined_db, que ser√° utilizado como o cat√°logo central da camada Refined do Data Lake. Esse database foi criado para registrar todas as tabelas modeladas, permitindo que os dados resultantes dos Jobs, fiquem organizados e acess√≠veis para consultas no Athena.

![Evid√™ncia 2](../Evid√™ncias/Evidencia2.png)

**Job**

Na camada Refined, optei por criar um job dedicado para cada tabela da modelagem dimensional, a fim de facilitar a organiza√ß√£o, reutiliza√ß√£o e manuten√ß√£o do c√≥digo, al√©m de permitir que cada processo de transforma√ß√£o seja executado e monitorado de forma independente. Essa abordagem tamb√©m permite isolar erros e adaptar cada job conforme a complexidade e origem dos dados utilizados.

O primeiro job criado foi o job_dim_tempo, respons√°vel por gerar a dimens√£o de tempo que ser√° usada como chave estrangeira na tabela fato do projeto. O job foi desenvolvido no AWS Glue, com o tipo Spark, linguagem Python 3 e vers√£o do Glue 3.0. Utilizei a role AWSGlueServiceRole-Lab4, com permiss√µes adequadas de leitura e escrita no bucket do S3. Configurei o job com worker type G 1x, escalonamento autom√°tico desativado, 2 workers fixos, tempo limite de 5 minutos e n√∫mero de tentativas igual a 0.

![Evid√™ncia 3](../Evid√™ncias/Evidencia3.png)

Para esse job, desenvolvi um script Python com o objetivo de criar a dimens√£o de tempo, que ser√° fundamental para a an√°lise temporal dos filmes na camada Refined. O script inicializa os contextos do Spark e do Glue, e em seguida l√™ a tabela csv_movies da camada Trusted, utilizando o Glue Catalog como origem, a l√≥gica do processamento parte da coluna anolancamento presente nos dados do CSV. Primeiramente, os valores nulos foram descartados e as duplica√ß√µes removidas, garantindo que cada ano apare√ßa apenas uma vez na dimens√£o. Em seguida, o campo foi renomeado para id_tempo, que atuar√° como chave substituta da dimens√£o, sendo usada como chave estrangeira na tabela fato para representar o tempo de forma padronizada. Foram tamb√©m criadas duas colunas adicionais: ano, com o valor do pr√≥prio ano de lan√ßamento, e decada, calculada com base no ano para facilitar an√°lises por per√≠odo. O DataFrame final foi gravado em formato Parquet na camada Refined, no caminho s3://data-compass-ana/Refined/DimTempo/, utilizando o modo overwrite para garantir que execu√ß√µes futuras substituam os dados anteriores. 

![Evid√™ncia 4](../Evid√™ncias/Evidencia4.png)


**Crawler**

Ap√≥s a execu√ß√£o do job respons√°vel pela cria√ß√£o da tabela, criei um Crawler com o nome crawler_dim_tempo. Para isso, utilizei a role AWSGlueServiceRole-Lab4, com permiss√µes adequadas para leitura e escrita no bucket S3 e para atualiza√ß√£o do Glue Data Catalog. Configurei o crawler para apontar para o diret√≥rio s3://data-compass-ana/Refined/DimTempo/, onde os dados da dimens√£o foram gravados no formato Parquet. Durante a configura√ß√£o, associei o crawler ao database filmes_refined_db, garantindo que a tabela dimtempo fosse criada com os metadados corretos e ficasse dispon√≠vel para consultas no Athena.


![Evid√™ncia 5](../Evid√™ncias/Evidencia5.png)

**Valida√ß√£o no Athena**

Para finalizar o processo e validar a cria√ß√£o da tabela dimtempo, acessei o AWS Athena e realizei uma consulta simples utilizando SELECT * FROM dimtempo LIMIT 10;. Essa consulta permitiu verificar a estrutura da tabela e confirmar que os dados foram carregados corretamente, com as colunas id_tempo, ano e decada devidamente preenchidas.

![Evid√™ncia 6](../Evid√™ncias/Evidencia6.png)



## 1.3 Dimens√£o Pa√≠s

**Job**

Criei o job job_dim_pais no AWS Glue com as mesmas configura√ß√µes adotadas no job anterior: utilizei a role AWSGlueServiceRole-Lab4, habilitada com permiss√µes de leitura e escrita no bucket do S3. O job foi configurado com tipo Spark, vers√£o do Glue 3.0, linguagem Python 3, worker type G 1x, sem escalonamento autom√°tico, com 2 workers fixos, zero tentativas e tempo m√°ximo de execu√ß√£o de 5 minutos.

![Evid√™ncia 7](../Evid√™ncias/Evidencia7.png)


Para o job_dim_pais, desenvolvi um script em Python com o objetivo de construir a dimens√£o de pa√≠ses a partir dos dados da tabela tmdb_movies presentes na camada Trusted. Inicialmente, o script carrega os dados com origin_country e production_countries, que aparecem de forma aninhada no JSON original da API TMDB. A primeira transforma√ß√£o extrai os pa√≠ses de origem dos filmes com a fun√ß√£o explode, gerando uma coluna chamada id_pais com os c√≥digos dos pa√≠ses. Em paralelo, outra transforma√ß√£o extrai os nomes dos pa√≠ses a partir da estrutura production_countries, acessando os campos iso_3166_1 e name. Ambas as extra√ß√µes passam por remo√ß√£o de duplicatas e nulos. Em seguida, as duas bases s√£o unidas pela chave id_pais, garantindo que cada pa√≠s seja representado apenas uma vez na dimens√£o final. A tabela resultante cont√©m os campos id_pais (c√≥digo ISO) e nome_pais, sendo ent√£o gravada em formato Parquet no S3, no caminho s3://data-compass-ana/Refined/DimPais/. Utilizei o modo overwrite para garantir que execu√ß√µes subsequentes atualizem os dados corretamente. Essa dimens√£o √© essencial para permitir an√°lises por pa√≠s de origem dos filmes na camada Refined.

![Evid√™ncia 8](../Evid√™ncias/Evidencia8.png)


**Crawler**

Ap√≥s executar o job, criei o crawler_dim_pais, usei role AWSGlueServiceRole-Lab4, configurei o crawler para apontar para o diret√≥rio onde os arquivos Parquet da dimens√£o foram gravados, ou seja, s3://data-compass-ana/Refined/DimPais/. O crawler foi vinculado ao banco de dados filmes_refined_db. Com a execu√ß√£o do crawler, os metadados da dimpais foram automaticamente extra√≠dos e registrados no Glue Data Catalog, permitindo que a tabela seja consultada facilmente via Athena.


![Evid√™ncia 9](../Evid√™ncias/Evidencia9.png)

**Valida√ß√£o no Athena**

Validei a cria√ß√£o da tabela dimpais acessando o Athena e realizando uma consulta simples, assim, observei que ao total temos 52 pa√≠ses, al√©m de verificar se a estrutura da tabela estava correta.

![Evid√™ncia 10](../Evid√™ncias/Evidencia10.png)


## 1.4 Dimens√£o Diretor

**Job**

Assim como nas dimens√µes anteriores, criei o job_dim_diretor no AWS Glue com o objetivo de processar e estruturar os dados dos diretores presentes na camada Trusted. O job foi configurado com o tipo Spark, Glue Version 3.0, linguagem Python 3, e executado com a role AWSGlueServiceRole-Lab4. Mantive as mesmas configura√ß√µes de performance: worker type G 1x, escalonamento autom√°tico desativado, dois workers fixos, sem tentativas adicionais e com tempo limite de 5 minutos. Esse job √© parte da estrat√©gia de dividir as transforma√ß√µes por tabela, o que facilita o gerenciamento, a depura√ß√£o e a reutiliza√ß√£o dos scripts na arquitetura do projeto.

![Evid√™ncia 11](../Evid√™ncias/Evidencia11.png)

Para construir a tabela dimdiretor, tive como objetivo extrair apenas os profissionais que exerceram a fun√ß√£o de diretor nos filmes provenientes da base da API TMDB. Como os dados de equipe t√©cnica estavam organizados em uma lista na coluna credits.crew, precisei aplicar a fun√ß√£o explode para transformar cada membro da equipe em uma linha individual, facilitando o filtro e a manipula√ß√£o posterior. Em seguida, apliquei um filtro para selecionar apenas os registros cujo campo job era igual a ‚ÄúDirector‚Äù, garantindo que apenas os diretores fossem mantidos.

Depois disso, selecionei os campos relevantes para compor a dimens√£o: o id_diretor, convertido para string, que funcionar√° como chave prim√°ria da tabela, o nome_diretor e o genero, tamb√©m convertido para string. Esse √∫ltimo campo segue a codifica√ß√£o do TMDB, onde 0 representa g√™nero n√£o especificado, 1 feminino e 2 masculino. Para evitar duplicidade de registros, apliquei a fun√ß√£o dropDuplicates considerando apenas o identificador do diretor. Por fim, salvei os dados processados em formato Parquet na camada Refined, no caminho s3://data-compass-ana/Refined/DimDiretor/. 


![Evid√™ncia 12](../Evid√™ncias/Evidencia12.png)


**Crawler**

Ap√≥s a finaliza√ß√£o do job que gerou a dimens√£o de diretores, criei o crawler_dim_diretor, utilizando a role AWSGlueServiceRole-Lab4, apontei o caminho s3://data-compass-ana/Refined/DimDiretor/, onde os arquivos Parquet da dimens√£o foram armazenados. Em seguida, defini o filmes_refined_db como banco de dados de destino, garantindo que a tabela dimdiretor fosse criada e catalogada corretamente.

![Evid√™ncia 13](../Evid√™ncias/Evidencia13.png)

**Valida√ß√£o no Athena**

Validei a cria√ß√£o da tabela dimdiretor acessando o Athena e realizando uma consulta simples com SELECT * FROM, assim, observei que ao total temos 495 diretores, al√©m de verificar se a estrutura da tabela estava correta.

![Evid√™ncia 30](../Evid√™ncias/Evidencia30.png)


## 1.5 Dimens√£o Artista

**Job**

Dando continuidade √† constru√ß√£o da camada Refined, criei o job job_dim_artista no AWS Glue. Mantive as mesmas configura√ß√µes dos jobs anteriores: linguagem Python, Glue Version 3.0, tipo Spark, execu√ß√£o com 2 workers do tipo G.1X e sem escalonamento autom√°tico. O job foi configurado com a role AWSGlueServiceRole-Lab4, o caminho de sa√≠da foi definido como s3://data-compass-ana/Refined/DimArtista/, e ao final da execu√ß√£o, os dados transformados foram gravados no formato Parquet.

![Evid√™ncia 14](../Evid√™ncias/Evidencia14.png)

Para construir a tabela de dimens√£o de artistas, iniciei carregando os dados da tabela tmdb_movies, j√° presente na camada Trusted, por meio do Glue Data Catalog. Como o campo credits.cast dentro dessa estrutura √© um array com os membros do elenco de cada filme, utilizei a fun√ß√£o explode para desaninh√°-lo, gerando uma linha para cada artista relacionado ao filme. A partir disso, selecionei as colunas relevantes para a dimens√£o: o id do artista, o nome e o g√™nero, renomeando os campos para id_artista, nome_artista e genero. Tamb√©m converti os campos id e gender para o tipo string, garantindo consist√™ncia no schema da tabela. Em seguida, eliminei os registros duplicados com base no id_artista, para garantir que cada artista aparecesse apenas uma vez na dimens√£o. Por fim, escrevi o DataFrame resultante em formato Parquet no bucket S3, no caminho s3://data-compass-ana/Refined/DimArtista/, utilizando o modo overwrite para substituir dados anteriores em execu√ß√µes futuras do job. Essa tabela servir√° como refer√™ncia para outras tabelas da modelagem, como a ponte FilmeArtista, que ligar√° os artistas aos seus respectivos pap√©is em cada filme.


![Evid√™ncia 15](../Evid√™ncias/Evidencia15.png)


**Crawler**

Ap√≥s a cria√ß√£o do job da dimens√£o de artistas, configurei o crawler_dim_artista utilizando a role AWSGlueServiceRole-Lab4, apontei o crawler para o caminho s3://data-compass-ana/Refined/DimArtista/, onde os arquivos Parquet da dimens√£o foram salvos. Em seguida, defini o database filmes_refined_db como destino para catalogar os metadados extra√≠dos.

![Evid√™ncia 16](../Evid√™ncias/Evidencia16.png)

**Valida√ß√£o no Athena**

Validei a cria√ß√£o da tabela dimartista acessando o Athena e realizando uma consulta simples com SELECT * FROM e limitando a 10 registros, assim, observei como estavam organizados os dados e as colunas.

![Evid√™ncia 17](../Evid√™ncias/Evidencia17.png)


## 1.6 Ponte Filme Artista 

**Job**

Durante a modelagem dimensional, optei por criar a tabela ponte filme_artista para representar a rela√ß√£o de muitos-para-muitos existente entre filmes e artistas. Como um filme pode ter diversos artistas no elenco e um mesmo artista pode participar de v√°rios filmes, essa abordagem garante a integridade e flexibilidade das an√°lises, permitindo cruzar informa√ß√µes entre as dimens√µes sem redund√¢ncia. Essa tabela tamb√©m inclui o nome do papel interpretado, enriquecendo as possibilidades anal√≠ticas sobre a atua√ß√£o dos artistas nos filmes de guerra.

Para construir essa tabela, criei o job Glue job_filme_artista, seguindo a mesma configura√ß√£o dos jobs anteriores: utilizei o tipo Spark, linguagem Python 3, Glue Version 3.0, com a role AWSGlueServiceRole-Lab4 e permiss√µes adequadas de leitura e escrita no bucket S3. A estrutura√ß√£o foi feita para garantir o carregamento correto das rela√ß√µes entre filmes e artistas a partir dos dados da API TMDB, j√° organizados na camada Trusted. Ap√≥s o processamento, os dados foram gravados no caminho s3://data-compass-ana/Refined/FilmeArtista/ em formato Parquet, preparando o terreno para consultas otimizadas e an√°lises futuras via Athena.

![Evid√™ncia 18](../Evid√™ncias/Evidencia18.png)

Para construir a tabela ponte filmeartista, desenvolvi um job Glue com o objetivo de mapear as rela√ß√µes entre os filmes e seus respectivos membros do elenco, garantindo a estrutura de muitos-para-muitos entre dimfilme e dimartista. Essa estrutura √© essencial para an√°lises detalhadas sobre participa√ß√£o de artistas nos filmes, permitindo, por exemplo, avaliar a presen√ßa feminina no elenco, a recorr√™ncia de atores em produ√ß√µes de guerra, ou a diversidade de pap√©is ao longo do tempo.

No c√≥digo, iniciei lendo os dados da tabela tmdb_movies, que se encontra na camada Trusted. Utilizei o campo credits.cast, que cont√©m informa√ß√µes sobre os atores e atrizes, incluindo ID, nome, personagem e ordem de apari√ß√£o no elenco. Como esse campo √© um array, utilizei a fun√ß√£o explode para transformar cada item do elenco em uma linha individual.

Em seguida, selecionei as colunas relevantes para a constru√ß√£o da tabela ponte: imdb_id, renomeado para id_filme, identificador do filme que ser√° para ligar √† fato; cast.id, renomeado para id_artista, identificador do artista, usado para se conectar √† dimartista; cast.character, renomeado como papel, nome do personagem interpretado pelo artista; cast.order, renomeado como ordem_elenco, posi√ß√£o do artista no cr√©dito do filme, o que pode ser √∫til para identificar pap√©is principais.

Apliquei um filtro com dropna para garantir que apenas registros com id_filme e id_artista v√°lidos fossem considerados, depois escrevi os dados processados no formato Parquet para o caminho s3://data-compass-ana/Refined/FilmeArtista/, usando o modo overwrite para substituir dados antigos em execu√ß√µes futuras. Essa tabela √© uma das pe√ßas centrais da modelagem, conectando os filmes com os artistas e possibilitando an√°lises robustas de representatividade, protagonismo e presen√ßa ao longo das d√©cadas.


![Evid√™ncia 19](../Evid√™ncias/Evidencia19.png)


**Crawler**

Ap√≥s a execu√ß√£o do job_filme_artista, criei o crawler_filme_artista, seguindo os mesmos passos das demais, assim, usei a role AWSGlueServiceRole-Lab4, com permiss√µes apropriadas de leitura e cataloga√ß√£o, configurei o crawler para apontar para o diret√≥rio S3 onde os dados transformados da tabela ponte foram gravados: s3://data-compass-ana/Refined/FilmeArtista/. O crawler foi vinculado ao database filmes_refined_db, garantindo que os metadados da tabela filmeartista fossem extra√≠dos e registrados no Glue Data Catalog. 

![Evid√™ncia 20](../Evid√™ncias/Evidencia20.png)

**Valida√ß√£o no Athena**

Validei a cria√ß√£o da tabela filmeartista acessando o Athena e realizando uma consulta simples com SELECT * FROM e limitando a 10 registros, assim, observei como estavam organizados os dados e as colunas.

![Evid√™ncia 21](../Evid√™ncias/Evidencia21.png)


## 1.7 Ponte Filme Diretor 

**Job**

Para representar corretamente a rela√ß√£o entre filmes e diretores no modelo dimensional, optaei tamb√©m por criar uma segunda tabela ponte, a filme_diretor. Essa decis√£o foi motivada pela natureza de relacionamento muitos-para-muitos entre essas entidades, um mesmo filme pode ter m√∫ltiplos diretores, e um diretor pode estar associado a v√°rios filmes ao longo do tempo. Dessa forma, a cria√ß√£o dessa ponte garante maior flexibilidade anal√≠tica, permitindo responder com precis√£o sobre  a evolu√ß√£o da representatividade de diretores ao longo das d√©cadas e se isso impactou de alguma forma na presen√ßa feminina no elenco.

Com base nisso, desenvolvi o job job_filme_diretor, que ser√° respons√°vel por extrair e estruturar essa rela√ß√£o a partir dos dados presentes na camada Trusted, preparando-os para a camada Refined. A configura√ß√£o seguiu o mesmo modelo dos jobs anteriores: utilizei o tipo Spark, linguagem Python 3, Glue Version 3.0, com a role AWSGlueServiceRole-Lab4 e permiss√µes adequadas de leitura e escrita no bucket S3. Ap√≥s o processamento, os dados foram gravados no caminho s3://data-compass-ana/Refined/FilmeDiretor/ em formato Parquet, preparando o terreno para consultas otimizadas e an√°lises futuras via Athena.


![Evid√™ncia 22](../Evid√™ncias/Evidencia22.png)

Iniciei o job carregando os dados da tabela tmdb_movies, localizada no database filmes_trusted_db, utilizando o Glue Catalog. Como essa tabela cont√©m uma estrutura aninhada com informa√ß√µes detalhadas da equipe t√©cnica de cada filme no campo credits.crew, utilizei a fun√ß√£o explode para transformar essa lista de profissionais em linhas individuais, com a estrutura expandida, filtrei apenas os registros cujo valor da coluna crew.job era igual a "Director", pois o objetivo era isolar os diretores dos demais membros da equipe t√©cnica. Em seguida, selecionei os campos relevantes para nossa tabela ponte: o imdb_id do filme, renomeado como id_filme, e o id do diretor, convertido para string e renomeado como id_diretor.

Apliquei o m√©todo dropDuplicates para garantir que n√£o houvesse duplicidades na rela√ß√£o entre filme e diretor, o que poderia ocorrer caso o mesmo diretor estivesse listado mais de uma vez em um √∫nico filme. Por fim, escrevi o resultado em formato Parquet no bucket S3, no caminho s3://data-compass-ana/Refined/FilmeDiretor/, utilizando o modo overwrite para permitir que execu√ß√µes futuras do job substituam os dados antigos com consist√™ncia. Essa transforma√ß√£o garantiu uma estrutura limpa e bem definida para analisar a participa√ß√£o dos diretores nos filmes de guerra ao longo do tempo.


![Evid√™ncia 23](../Evid√™ncias/Evidencia23.png)


**Crawler**

Ap√≥s a execu√ß√£o do job job_filme_diretor, criei o crawler_filme_diretor, respons√°vel por catalogar os dados transformados da tabela ponte que relaciona filmes e diretores. Para isso, utilizei a role AWSGlueServiceRole-Lab4, configurei o crawler para apontar para o caminho s3://data-compass-ana/Refined/FilmeDiretor/, onde os arquivos Parquet foram salvos. Em seguida, defini o database filmes_refined_db como destino da nova tabela catalogada. Com isso, os metadados da tabela filmediretor ficaram dispon√≠veis no cat√°logo do Glue e acess√≠veis para consultas no Athena.

![Evid√™ncia 24](../Evid√™ncias/Evidencia24.png)

**Valida√ß√£o no Athena**

Validei a cria√ß√£o da tabela filmediretor acessando o Athena e realizando uma consulta simples com SELECT * FROM e limitando a 10 registros, assim, observei como estavam organizados os dados e as colunas.

![Evid√™ncia 25](../Evid√™ncias/Evidencia25.png)


## 1.8 Fato Representa√ß√£o Feminina

**Job**

Para consolidar todas as informa√ß√µes necess√°rias em uma √∫nica tabela de an√°lise, desenvolvi o job job_fato_rep_feminina, respons√°vel por gerar a tabela fato principal do projeto a partir das tabelas csv_movies e tmdb_movies, previamente estruturadas na camada Trusted. Esse job foi configurado seguindo o mesmo padr√£o adotado nos anteriores: utilizei o tipo Spark com linguagem Python 3, Glue Version 3.0, e a role AWSGlueServiceRole-Lab4, que j√° possu√≠a as permiss√µes adequadas de leitura e escrita no bucket S3.

Finalizada a transforma√ß√£o, os dados foram gravados no caminho s3://data-compass-ana/Refined/FatoRepresentacaoFeminina/, no formato Parquet e utilizando o modo overwrite, assegurando que execu√ß√µes futuras atualizem completamente os dados. Esse job foi essencial para consolidar o modelo dimensional do projeto, centralizando as informa√ß√µes necess√°rias para as an√°lises sobre a representatividade feminina nos filmes de guerra.

![Evid√™ncia 26](../Evid√™ncias/Evidencia26.png)

Para construir a tabela fato FatoRepresentacaoFeminina, iniciei realizando a jun√ß√£o entre os dados do csv_movies e do tmdb_movies, pois meu objetivo era manter na tabela fato apenas os filmes que estivessem presentes nas duas fontes. Essa decis√£o se baseia no fato de que os dados extra√≠dos da API do TMDB j√° estavam previamente filtrados com base nos crit√©rios do projeto: filmes de guerra lan√ßados a partir de 1950, com nota m√©dia maior ou igual a 6 e pelo menos 100 votos. Como o CSV estava estruturado com uma linha por artista, fazer o join considerando apenas os filmes que estavam presentes no TMDB garantiu automaticamente a aplica√ß√£o desses filtros, sem a necessidade de reprocess√°-los diretamente no CSV.

Ap√≥s o join, apliquei uma janela particionada por id do filme, ordenando pelo maior n√∫mero de votos. Isso foi necess√°rio porque no CSV existem m√∫ltiplas entradas por filme, uma para cada artista, e eu queria selecionar apenas uma linha representativa de cada filme para a tabela fato. Dessa forma, mantive apenas a linha com maior n√∫mero de votos por id, garantindo que cada filme aparecesse uma √∫nica vez na tabela.

Em seguida, selecionei as colunas mais relevantes para a an√°lise: o id_filme e os t√≠tulos principal e original, para fins de identifica√ß√£o; o ano_lancamento, que √© uma vari√°vel temporal fundamental para o projeto; o id_pais, que foi extra√≠do como o primeiro elemento da lista de pa√≠ses de origem fornecida pelo TMDB, assumindo que ele representa o pa√≠s principal da produ√ß√£o; al√©m disso, inclu√≠ as m√©tricas nota_media, numero_votos e popularidade, que ser√£o √∫teis em diversas an√°lises sobre recep√ß√£o e relev√¢ncia dos filmes.

Com o ano de lan√ßamento em m√£os, relacionei essa informa√ß√£o com a dimens√£o dimtempo por meio da coluna ano, de onde trouxe a chave substituta id_tempo para estruturar a an√°lise temporal da tabela fato. Para enriquecer a tabela com informa√ß√µes sobre a autoria dos filmes, tamb√©m fiz um join com a tabela ponte filmediretor, agrupando os dados para obter uma lista com todos os id_diretores associados a cada filme, visto que um mesmo filme pode ter mais de um diretor.

O resultado final foi uma tabela fato consolidada e granular, onde cada linha representa um filme √∫nico que atende aos crit√©rios definidos para a an√°lise da representatividade feminina em filmes de guerra. Essa tabela √© a base central da modelagem dimensional do projeto e permitir√° a an√°lise cruzada com as dimens√µes de tempo, pa√≠s, artista e diretor. Por fim, escrevi o resultado em formato Parquet na camada Refined do S3 no caminho: s3://data-compass-ana/Refined/FatoRepresentacaoFeminina/, utilizando o modo overwrite para garantir que execu√ß√µes futuras possam substituir os dados corretamente.


![Evid√™ncia 27](../Evid√™ncias/Evidencia27.png)


**Crawler**

Ap√≥s a execu√ß√£o do job_fato_rep_feminina, criei o crawler_fato_rep_feminina com o objetivo de catalogar a nova tabela fato na camada Refined do Data Lake. Para isso, utilizei novamente a role AWSGlueServiceRole-Lab4, que j√° estava configurada com as permiss√µes adequadas para leitura no bucket S3 e atualiza√ß√£o do Glue Data Catalog. Apontei o crawler para o caminho s3://data-compass-ana/Refined/FatoRepresentacaoFeminina/, onde os dados foram gravados em formato Parquet durante o job. Em seguida, configurei o crawler para armazenar os metadados no database filmes_refined_db, centralizando todas as tabelas do projeto. Com isso, a tabela fato ficou dispon√≠vel para consultas no Athena.

![Evid√™ncia 28](../Evid√™ncias/Evidencia28.png)

**Valida√ß√£o no Athena**

Para concluir a cria√ß√£o da tabela fato, acessei o AWS Athena e realizei uma consulta simples utilizando SELECT * FROM fatorepresentacaofeminina;. Essa verifica√ß√£o teve como objetivo confirmar se a tabela havia sido corretamente catalogada, se as colunas foram criadas conforme esperado e se os dados estavam consistentes. O resultado da consulta demonstrou que a estrutura da tabela estava √≠ntegra e com todas as colunas esperadas presentes. Al√©m disso obtive como retorno 511 registros √∫nicos de filmes, o que validou com sucesso o processamento realizado pelo job_fato_rep_feminina e encerrou essa etapa da Sprint com √™xito.

![Evid√™ncia 29](../Evid√™ncias/Evidencia29.png)







