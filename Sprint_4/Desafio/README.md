# üöÄ Desafio 

## üìå Resumo

Neste desafio da Sprint 4, trabalhei com o conjunto de dados "chegadas_2024.csv", que re√∫ne informa√ß√µes sobre a chegada de turistas ao Brasil em 2024. O objetivo foi realizar o tratamento, an√°lise e visualiza√ß√£o dos dados, respondendo a questionamentos estrat√©gicos definidos previamente. Na primeira etapa, realizei uma an√°lise explorat√≥ria inicial com pandas no Jupyter Notebook. Por meio da an√°lise inicial do arquivo, foi poss√≠vel identificar as principais informa√ß√µes para compreender o comportamento da chegada de turistas ao Brasil ao longo do ano, baseado nisso, selecionei tr√™s questionamentos principais que considerei estrat√©gicos para gerar insights sobre o fluxo tur√≠stico no pa√≠s. Ap√≥s isso,criei um bucket S3 via script em Python e enviei o arquivo original para a nuvem. 

Na etapa seguinte, li o arquivo do bucket, tratei os dados e apliquei seis tipos de manipula√ß√µes obrigat√≥rias (filtros com operadores l√≥gicos, fun√ß√µes de agrega√ß√£o, condi√ß√µes, convers√µes, manipula√ß√µes de datas e de strings), respondendo aos tr√™s questionamentos, tamb√©m foi gerado gr√°ficos com Matplotlib. Ao final, os resultados obtidos em cada an√°lise e o arquivo csv limpo foram salvos na pasta Etapa3, para que pudessem ser enviados ao bucket criado para o desafio.

Na √∫ltima etapa, desenvolvi um script para enviar o CSV limpo e os gr√°ficos gerados para o bucket criado anteriormente, utilizando as bibliotecas boto3 e dotenv para autentica√ß√£o e integra√ß√£o com a AWS. O desenvolvimento foi organizado em etapas, desde a prototipa√ß√£o inicial at√© a execu√ß√£o final integrada, detalhadas nas se√ß√µes a seguir, contendo os arquivos e as evid√™ncias de cada etapa:


## üóÇÔ∏è Sum√°rio 

1. [Etapa 1](#etapa-1)
2. [Etapa 2](#etapa-2)
3. [Etapa 3](#etapa-3)


<br>

---

# Etapa 1

Nessa etapa do desafio, foi realizada a leitura de um arquivo oriundo do portal de dados p√∫blicos do Governo Brasileiro, o csv "chegadas_2024.csv" em que re√∫ne dados relativos √†s estimativas do fluxo de chegadas de turistas internacionais (incluindo turistas estrangeiros e brasileiros que residem no exterior) ao Brasil, desagregadas por pa√≠s de resid√™ncia permanente, por m√™s e via de acesso (a√©rea, terrestre, mar√≠tima ou fluvial). Assim, foi feito um tratamento de dados inicial para posteriormente analisar as informa√ß√µes contidas no mesmo. Segui uma sequ√™ncia de a√ß√µes nas quais estarei detalhando um pouco mais sobre os c√≥digos que usei para execu√ß√£o dos passos. Seguem os arquivos utilizados nessa etapa:

| Arquivo | Link |
|--------|------|
| chegadas_2024 | [üîó chegadas_2024](./Etapa1/chegadas_2024.csv) |
| Etapa1.ipynb| [üîó Etapa1.ipynb](./Etapa1/Etapa1.ipynb) |

<br>

> Explica√ß√£o do c√≥digo


**An√°lise inicial**

Inicialmente importei a biblioteca pandas para an√°lise e tratamento dos dados, durante a an√°lise inicial do conjunto de dados chegadas_2024.csv, ao tentar carreg√°-lo com pd.read_csv(), ocorreu um erro relacionado √† codifica√ß√£o do arquivo. Para identificar o encoding correto, utilizei a biblioteca chardet, que indicou a codifica√ß√£o 'ISO-8859-1'. Ap√≥s ajustar o par√¢metro de codifica√ß√£o, ainda enfrentei um erro de tokeniza√ß√£o devido ao separador de colunas, que n√£o era a v√≠rgula padr√£o. Especificando o separador como ';', foi poss√≠vel realizar a leitura correta do arquivo e visualizar suas primeiras entradas e informa√ß√µes gerais.

Al√©m disso, importei as bibliotecas boto3 e botocore.exceptions para realizar opera√ß√µes com o servi√ßo Amazon S3, como a cria√ß√£o do bucket e o envio de arquivos para a nuvem. Tamb√©m utilizei dotenv para carregar vari√°veis de ambiente armazenadas no arquivo .env, garantindo seguran√ßa e flexibilidade na autentica√ß√£o, a biblioteca os tamb√©m foi utilizada para acessar essas vari√°veis carregadas.

Ap√≥s a leitura bem-sucedida do arquivo, iniciei a explora√ß√£o preliminar do conjunto de dados com o objetivo de compreender sua estrutura, caracter√≠sticas gerais e identificar poss√≠veis necessidades de limpeza ou transforma√ß√£o. Utilizei as seguintes fun√ß√µes do pandas: df.head(), df.tail(), df.shape, df.info(), df.nunique() e df.isnull().sum(). 

![Evid√™ncia 1](../Evid√™ncias/Evidencia1.png)

<br>

**Questionamentos**

Por meio da an√°lise inicial do arquivo, foi poss√≠vel identificar as principais informa√ß√µes para compreender o comportamento da chegada de turistas ao Brasil ao longo do ano. Com base nisso, selecionei tr√™s questionamentos principais que considero estrat√©gicos para gerar insights sobre o fluxo tur√≠stico no pa√≠s:

1. Classifica√ß√£o dos pa√≠ses por faixas de volume de turistas: a partir dessa an√°lise √© poss√≠vel identificar quais pa√≠ses enviaram mais turistas ao Brasil e quais apresentam menor representatividade;
2. Principais vias de entrada de turistas no Brasil: ajuda a entender por quais principais vias os turistas mais chegam ao pa√≠s;
3. Meses com maior n√∫mero de chegadas de turistas via a√©rea em 2024: mostra a sazonalidade do turismo ao longo do ano por meio das vias a√©reas.

<br>

**Cria√ß√£o do bucket e upload do arquivo**

Ap√≥s a an√°lise explorat√≥ria dos dados do arquivo chegadas_2024.csv, realizei o envio do mesmo para a nuvem utilizando o servi√ßo Amazon S3, garantindo que os dados estejam acess√≠veis para as pr√≥ximas etapas do projeto. Inicialmente, carreguei as vari√°veis de ambiente armazenadas no arquivo .env com a fun√ß√£o load_dotenv(), assegurando a seguran√ßa das credenciais de autentica√ß√£o (chave de acesso, segredo e token da sess√£o). Essas credenciais foram usadas para configurar o cliente do S3 via biblioteca boto3. Defini o nome do bucket como chegadas-turistas-2024-ana e, em seguida, executei sua cria√ß√£o por meio de um bloco try-except, tratando o cen√°rio em que o bucket j√° exista e seja de minha propriedade. Vale ressaltar que, como a regi√£o utilizada foi a us-east-1, a cria√ß√£o do bucket foi realizada sem o par√¢metro expl√≠cito de regi√£o, em conformidade com as regras da AWS para essa localidade. Com o bucket validado, o pr√≥ximo passo foi o upload do arquivo chegadas_2024.csv, tamb√©m encapsulado em um bloco de tratamento de exce√ß√µes para lidar com poss√≠veis falhas durante o envio.

Bucket criado:

![Evid√™ncia 2](../Evid√™ncias/Evidencia2.png)

Upload do arquivo CSV:

![Evid√™ncia 3](../Evid√™ncias/Evidencia3.png)


<br>

# Etapa 2

Nesta etapa do desafio, dei continuidade √† an√°lise dos dados sobre as chegadas de turistas ao Brasil em 2024. A partir do arquivo j√° armazenado no bucket do Amazon S3, realizei a leitura do dataset diretamente na aplica√ß√£o, criando um DataFrame com a biblioteca pandas.Em seguida, fiz o tratamento dos dados, deixando o CSV limpo e estruturado para a execu√ß√£o das tr√™s an√°lises estrat√©gicas definidas anteriormente. Para cada uma delas, apliquei pelo menos uma das manipula√ß√µes obrigat√≥rias: filtros com operadores l√≥gicos, fun√ß√µes de agrega√ß√£o, condi√ß√µes, convers√µes, manipula√ß√µes de datas e de strings, de forma que todas elas fossem utilizadas em algum momento. Ao final, os resultados obtidos em cada an√°lise e o arquivo csv limpo foram salvos na pasta Etapa3, para que pudessem ser enviados ao bucket criado para o desafio.

| Arquivo | Link |
|--------|------|
| Etapa2.ipynb| [üîó Etapa2.ipynb](./Etapa2/Etapa2.ipynb) |


<br>

> Explica√ß√£o do c√≥digo


**Importa√ß√£o inicial**

Para esta etapa, importei a biblioteca pandas para criar e manipular o DataFrame a partir do arquivo CSV armazenado no S3. Utilizei boto3 para acessar o servi√ßo Amazon S3 e realizar a leitura direta do arquivo, e botocore.exceptions para tratar poss√≠veis erros durante essa opera√ß√£o. As credenciais de acesso foram carregadas com a biblioteca dotenv, garantindo seguran√ßa ao utilizar o arquivo .env, enquanto a os foi usada para acessar essas vari√°veis no ambiente do sistema. Para ler o arquivo diretamente da nuvem sem salv√°-lo localmente, utilizei BytesIO, da biblioteca io, que permite trabalhar com os dados em mem√≥ria. A biblioteca unidecode foi usada para padronizar textos, removendo acentos e caracteres especiais, em rela√ß√£o ao tratamento de dados textuais. Por fim, importei matplotlib.pyplot e seaborn, que foram utilizadas para criar visualiza√ß√µes gr√°ficas que acompanham as an√°lises realizadas.

Ap√≥s o envio do arquivo chegadas_2024.csv para o Amazon S3, iniciei sua leitura diretamente da nuvem. Carreguei as credenciais de acesso com o dotenv, garantindo uma autentica√ß√£o segura junto √† AWS. Em seguida, configurei o cliente S3 com a biblioteca boto3, utilizando as vari√°veis de ambiente. Defini o nome do bucket e do arquivo a ser acessado, e utilizei o m√©todo get_object para recuperar o conte√∫do diretamente do S3. Com o BytesIO, li os dados em mem√≥ria e criei o DataFrame com pandas, especificando a codifica√ß√£o ISO-8859-1 e o separador ;, conforme o formato original do CSV. O c√≥digo foi encapsulado em blocos de tratamento de exce√ß√µes para identificar poss√≠veis erros na autentica√ß√£o, acesso ao bucket ou leitura dos dados. Com isso, o DataFrame foi carregado com sucesso, permitindo dar continuidade √†s an√°lises na pr√≥xima etapa do projeto.

![Evid√™ncia 4](../Evid√™ncias/Evidencia4.png)

<br>

**Limpeza inicial**

Ap√≥s a an√°lise inicial, observei a necessidade de padronizar os nomes das colunas. Para isso, removi espa√ßos em branco nas extremidades, converti os nomes para letras min√∫sculas, substitu√≠ espa√ßos por underscores e eliminei acentua√ß√£o, adotando a conven√ß√£o snake_case.

Converti as colunas continente, pa√≠s, UF, via e m√™s, que anteriormente estavam como object para o tipo category, otimizando o uso de mem√≥ria e facilitando an√°lises categ√≥ricas posteriores. Garanti que as colunas de c√≥digos num√©ricos, como cod_continente, cod_pais, cod_uf, cod_via e cod_mes, estivessem no tipo int64, garantindo a consist√™ncia dos dados e possibilitando opera√ß√µes num√©ricas com maior precis√£o. Por fim, utilizei df.dtypes para verificar se os tipos de dados de cada coluna estavam corretos ap√≥s o tratamento, confirmando, se colunas categ√≥ricas e num√©ricas estavam devidamente convertidas.

Ap√≥s concluir o tratamento inicial dos dados, salvei o DataFrame resultante em um novo arquivo CSV chamado chegadas_2024_limpo.csv, localizado na pasta Etapa3. Utilizei os par√¢metros sep=';' e encoding='ISO-8859-1' para manter a compatibilidade com o formato original. O argumento index=False foi especificado para evitar que o √≠ndice do DataFrame fosse adicionado como uma coluna no arquivo. Essa vers√£o limpa do dataset tamb√©m ser√° utilizada nas pr√≥ximas an√°lises da etapa 2.

![Evid√™ncia 5](../Evid√™ncias/Evidencia5.png)

<br>

**Q1: Classifica√ß√£o dos pa√≠ses por faixas de volume de turistas**

Nesta an√°lise, utilizei a fun√ß√£o groupby para agrupar os dados por pa√≠s e somar o total de chegadas de turistas por nacionalidade, consolidando as informa√ß√µes em uma linha por pa√≠s. Em seguida, calculei a m√©dia geral de turistas entre todos os pa√≠ses com mean(), que serviu de base para classificar o volume de chegadas. Para isso, defini a fun√ß√£o condicional faixa_volume, que classifica os pa√≠ses em tr√™s categorias: Alto, M√©dio e Baixo, com base em m√∫ltiplos da m√©dia geral (mais de 1,5 vezes a m√©dia √© ‚ÄúAlto‚Äù, entre 0,5 e 1,5 vezes √© ‚ÄúM√©dio‚Äù, abaixo de 0,5 √© ‚ÄúBaixo‚Äù). A fun√ß√£o foi aplicada √† coluna chegadas usando apply() para gerar a nova coluna faixa_volume. Por fim, filtrei os pa√≠ses classificados com volume Alto, ordenei os dados de forma decrescente pelo total de chegadas e selecionei os 10 primeiros, destacando as principais nacionalidades que mais visitaram o Brasil.

Manipula√ß√µes obrigat√≥rias utilizadas:

- Fun√ß√£o de agrega√ß√£o: sum() para totalizar as chegadas por pa√≠s.
- Fun√ß√£o condicional: faixa_volume() classifica os valores com base em regras.

![Evid√™ncia 6](../Evid√™ncias/Evidencia6.png)

<br>

**Gr√°fico Q1: Top 20 Pa√≠ses por Chegadas de Turistas ao Brasil**

Para construir o gr√°fico, selecionei os 20 pa√≠ses com maior n√∫mero de chegadas de turistas ao Brasil, ordenando o DataFrame df_paises pela coluna chegadas em ordem decrescente e utilizando o m√©todo head(20) para filtrar esses pa√≠ses. Defini uma paleta de cores personalizada em tons de azul, associando cores diferentes para cada faixa de volume de turistas. Em seguida, criei um gr√°fico de barras horizontais com a biblioteca seaborn, configurando o eixo y para os nomes dos pa√≠ses e o eixo x para o n√∫mero de chegadas. Usei o par√¢metro hue para colorir as barras conforme a faixa de volume, apliquei a paleta personalizada e defini dodge=False para que as barras fiquem agrupadas por pa√≠s. Ajustei o tamanho da figura para uma visualiza√ß√£o equilibrada e formatei t√≠tulo, r√≥tulos dos eixos e legenda para melhor clareza. A fun√ß√£o tight_layout() organizou os elementos para evitar sobreposi√ß√µes. Ap√≥s exibir o gr√°fico com plt.show(), salvei a imagem gerada no caminho definido dentro da pasta Etapa3 com alta resolu√ß√£o (300 dpi), garantindo seu uso nas pr√≥ximas etapas do projeto.

![Evid√™ncia 7](../Evid√™ncias/Evidencia7.png)

<br>

**Q2: Principais vias de entrada de turistas no Brasil:**

Nesta an√°lise, antes de realizar o agrupamento, utilizei fun√ß√µes de string para padronizar os nomes da coluna via, removendo espa√ßos em branco e convertendo todos os textos para letras min√∫sculas, evitando duplicidades causadas por varia√ß√µes na grafia. Em seguida, agrupei os dados por via de entrada com groupby, somando o total de turistas que chegaram ao Brasil por cada tipo de via. Ap√≥s o agrupamento, utilizei uma fun√ß√£o de convers√£o para garantir que a coluna chegadas estivesse no tipo inteiro, assegurando consist√™ncia no tipo de dado. Por fim, ordenei os resultados de forma decrescente pelo n√∫mero total de chegadas, permitindo identificar as principais vias de entrada utilizadas pelos turistas.

Manipula√ß√µes obrigat√≥rias utilizadas:

- Fun√ß√£o de agrega√ß√£o: sum() para totalizar o n√∫mero de chegadas por via.
- Fun√ß√£o de string: .str.strip().str.lower() para padronizar os valores textuais da coluna via.
- Fun√ß√£o de convers√£o: astype(int) para garantir o tipo inteiro na coluna chegadas.

![Evid√™ncia 8](../Evid√™ncias/Evidencia8.png)

<br>

**Gr√°fico Q2: Distribui√ß√£o das Principais Vias de Entrada de Turistas no Brasil**

Este gr√°fico de pizza mostra a propor√ß√£o percentual das principais vias de entrada de turistas no Brasil. Para constru√≠-lo, criei as vari√°veis vias e chegadas, extra√≠das do DataFrame df_vias, representando os nomes das vias e o total de chegadas, respectivamente. Defini uma paleta de cores em tons de azul para diferenciar as categorias. Utilizei plt.figure() para ajustar o tamanho da imagem e plt.pie() para gerar o gr√°fico, com autopct='%1.1f%%' para exibir os percentuais, pctdistance e labeldistance para posicionamento dos textos e bordas brancas entre as fatias para facilitar a visualiza√ß√£o. Adicionei uma legenda com plt.legend(), formatei os textos com plt.setp(), e finalizei com t√≠tulo, tight_layout() para ajustar os elementos e plt.savefig() para salvar o gr√°fico na pasta Etapa3 antes de exibi-lo com plt.show().

![Evid√™ncia 9](../Evid√™ncias/Evidencia9.png)

<br>

**Q3: Meses com maior n√∫mero de chegadas de turistas via a√©rea em 2024**

Nesta an√°lise, apliquei uma filtragem composta para selecionar apenas os registros do ano de 2024 e com via de entrada a√©rea, utilizando dois operadores l√≥gicos para garantir a precis√£o da amostra. Antes disso, criei uma nova coluna de data combinando as colunas ano e cod_mes com fun√ß√µes de string e convers√£o, transformando-as em um objeto datetime. A partir dessa nova coluna, extra√≠ o nome do m√™s em ingl√™s com dt.strftime(), facilitando a identifica√ß√£o dos per√≠odos. Em seguida, agrupei os dados por c√≥digo do m√™s, nome em portugu√™s e nome em ingl√™s, somando o total de chegadas com a fun√ß√£o de agrega√ß√£o sum(). Por fim, ordenei os dados do maior para o menor n√∫mero de chegadas, destacando os meses com maior volume de turismo internacional por via a√©rea.

Manipula√ß√µes obrigat√≥rias utilizadas:

- Cl√°usula com dois operadores l√≥gicos: filtro por ano e via (== e &).
- Fun√ß√£o de data: cria√ß√£o da coluna data com pd.to_datetime() e extra√ß√£o do m√™s com dt.strftime('%B').

![Evid√™ncia 10](../Evid√™ncias/Evidencia10.png)

<br>

**Gr√°fico Q3: N√∫mero de Chegadas por M√™s (Via A√©rea - 2024)**

Este gr√°fico de barras mostra o total de turistas que chegaram ao Brasil por via a√©rea em cada m√™s do ano de 2024. Para constru√≠-lo, utilizei o DataFrame df_meses_ordenado, que j√° cont√©m os meses e os respectivos totais de chegadas, ordenados do maior para o menor volume. A fun√ß√£o plt.figure() foi usada para definir o tamanho da figura, enquanto plt.bar() gerou as barras, aplicando uma cor azul com bordas pretas para destacar cada m√™s. Configurei os eixos com os r√≥tulos adequados, adicionei rota√ß√£o nas categorias do eixo x para melhor leitura e defini um t√≠tulo informativo. Utilizei plt.tight_layout() para garantir o espa√ßamento adequado dos elementos, plt.savefig() para salvar o gr√°fico na pasta Etapa3 e finalizei com plt.show() para exibir a visualiza√ß√£o.

![Evid√™ncia 11](../Evid√™ncias/Evidencia11.png)

<br>

# Etapa 3

Nesta etapa do desafio, foi realizado o envio do arquivo CSV limpo, chegadas_2024_limpo.csv, e dos gr√°ficos gerados na etapa 2 (grafico_top20_paises.png, grafico_vias_pizza.png e grafico_chegadas_por_mes.png) correspondentes aos questionamentos analisados, para o bucket 'chegadas-turistas-2024-ana', criado na etapa 1. Esses arquivos est√£o armazenados localmente na pasta Etapa3, organizados e prontos para upload, garantindo que os resultados da an√°lise estejam dispon√≠veis de forma estruturada na nuvem.


| Arquivo | Link |
|--------|------|
| Etapa3.ipynb| [üîó Etapa3.ipynb](./Etapa3/Etapa3.ipynb) |
| chegadas_2024_limpo.csv| [üîó chegadas_2024_limpo.csv](./Etapa3/chegadas_2024_limpo.csv) |
| grafico_chegadas_por_mes.png| [üîó grafico_chegadas_por_mes.png](./Etapa3/grafico_chegadas_por_mes.png) |
| grafico_top20_paises.png| [üîó grafico_top20_paises.png](./Etapa3/grafico_top20_paises.png) |
| grafico_vias_pizza.png| [üîó grafico_vias_pizza.png](./Etapa3/grafico_vias_pizza.png) |

<br>

> Explica√ß√£o do c√≥digo


**Upload dos arquivos**

Inicialmente importei as bibliotecas necess√°rias para a intera√ß√£o com o sistema operacional e com a AWS, al√©m do gerenciamento de vari√°veis de ambiente e tratamento de exce√ß√µes. A biblioteca os permite manipular caminhos de arquivos e vari√°veis do sistema operacional. boto3 √© o SDK oficial da AWS para Python, utilizado para interagir com servi√ßos da AWS, como o S3, facilitando o upload dos arquivos ao bucket. Para carregar as vari√°veis de ambiente definidas no arquivo .env, utilizei o load_dotenv da biblioteca dotenv, garantindo que credenciais e configura√ß√µes sens√≠veis ficassem protegidas. Por fim, importei ClientError da botocore.exceptions para capturar e tratar erros espec√≠ficos que possam ocorrer durante a comunica√ß√£o com a AWS.

Comecei o c√≥digo carregando as vari√°veis de ambiente do arquivo .env com load_dotenv(), permitindo acessar as credenciais da AWS de forma segura por meio do dicion√°rio env. Em seguida, inicializei o cliente do S3 usando boto3.client(), passando as credenciais e a regi√£o obtidas do ambiente. Defini o nome do bucket S3 onde os arquivos seriam enviados e criei um dicion√°rio arquivos_para_upload, que mapeia os caminhos locais dos arquivos aos nomes que ter√£o no bucket. No loop for, percorri cada arquivo, abrindo em modo bin√°rio e utilizando s3.upload_fileobj() para fazer o upload para o bucket. Caso o arquivo local n√£o fosse encontrado, o erro FileNotFoundError era capturado e uma mensagem era exibida. Se houvesse algum problema na comunica√ß√£o com o S3, a exce√ß√£o ClientError era tratada com uma mensagem detalhada. Ao final, o c√≥digo exibe a confirma√ß√£o do sucesso no envio de cada arquivo.


![Evid√™ncia 12](../Evid√™ncias/Evidencia12.png)

<br>

Arquivos carregados no bucket:

![Evid√™ncia 13](../Evid√™ncias/Evidencia13.png)

