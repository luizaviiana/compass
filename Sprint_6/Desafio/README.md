# üöÄ Desafio 

## üìå Resumo

Nesse desafio dei continuidade √† terceira etapa do projeto, o foco foi o processamento e organiza√ß√£o dos dados na camada Trusted do Data Lake, utilizando o servi√ßo AWS Glue para transformar os arquivos da camada Raw. Para isso, criei dois jobs em Glue, um para processar os arquivos CSV e outro para os dados da API TMDB no formato JSON, convertendo-os para o formato Parquet e organizando-os conforme o padr√£o de estrutura definido para o projeto.

Em seguida, configurei e executei crawlers para catalogar esses dados na camada Trusted, garantindo a cria√ß√£o das tabelas no Glue Data Catalog dentro do database dedicado ao projeto. Finalizei a etapa com a valida√ß√£o dos dados via AWS Athena, conferindo a exist√™ncia das tabelas e a possibilidade de consultas SQL para suportar an√°lises futuras. Essa etapa consolidou a organiza√ß√£o da camada Trusted, facilitando o acesso e a consulta dos dados de forma eficiente e padronizada, al√©m de preparar a base para os pr√≥ximos passos do projeto.


## üóÇÔ∏è Sum√°rio 

1. [Etapa 3](#etapa-3)

<br>

---

# Etapa 3

A seguir estarei detalhando um pouco mais dos scripts utilizados em cada etapa, de como foi a execu√ß√£o e as evid√™ncias de cada a√ß√£o tomada:

| Arquivo | Link |
|--------|------|
| glue_job_csv | [üîó glue_job_csv ](./glue_job_csv.py) |
| glue_job_tmdb | [üîó glue_job_tmdb ](./glue_job_tmdb.py) |
<br>

> Explica√ß√£o 

**Data Catalog**

Para o desafio, iniciei criando o Glue Database com o nome filmes_trusted_db, esse banco de dados servir√° como cat√°logo central para registrar as tabelas da camada Trusted, permitindo que os dados processados pelos jobs do AWS Glue fiquem acess√≠veis via AWS Athena para futuras an√°lises.

![Evid√™ncia 1](../Evid√™ncias/evidencia1.png)

**Job + Crawler para CSV**

Para dar continuidade ao processamento dos dados CSV, criei um job no AWS Glue com o nome job_process_movies_csv, utilizando a role AWSGlueServiceRole-Lab4 com permiss√µes de leitura e escrita no bucket. Mantive o tipo Spark, com Glue Version 3.0 e linguagem Python 3. Configurei o job com o worker type G 1x, com escalonamento autom√°tico desativado e n√∫mero fixo de 2 workers. Tamb√©m defini o n√∫mero de tentativas como 0 e um tempo limite de execu√ß√£o de 5 minutos. 

![Evid√™ncia 2](../Evid√™ncias/evidencia2.png)

Para esse job, desenvolvi um script Python para o AWS Glue Job com o objetivo de processar o arquivo movies.csv localizado na camada Raw do S3. O script inicializa o contexto do Glue e do Spark, define o caminho de origem para o arquivo CSV e realiza sua leitura utilizando o separador pipe, para facilitar o monitoramento, inclu√≠ prints que exibem o total de linhas lidas e o caminho onde os dados ser√£o gravados. O DataFrame resultante √© ent√£o gravado em formato Parquet na camada Trusted do S3, seguindo a estrutura definida em s3://data-compass-ana/Trusted/Local/Parquet/Movies/. Como que n√£o era necess√°rio realizar tratamento nesta etapa, apenas converti o DataFrame original para o formato Parquet, e utilizei o modo overwrite para garantir que execu√ß√µes subsequentes substituam os dados anteriores, o job √© finalizado com o comando job.commit() para registrar o t√©rmino da execu√ß√£o.

![Evid√™ncia 3](../Evid√™ncias/evidencia3.png)

![Evid√™ncia 4](../Evid√™ncias/evidencia4.png)

Para a etapa de cataloga√ß√£o dos dados processados, criei um Glue Crawler chamado crawler_movies_csv. Utilizei a role de execu√ß√£o AWSGlueServiceRole-Lab4, que possui as permiss√µes necess√°rias para acessar os dados no bucket S3 e atualizar o Glue Data Catalog. Configurei o crawler para apontar para o caminho do S3 onde os arquivos Parquet do arquivo movies.csv foram gravados, ou seja, s3://data-compass-ana/Trusted/Local/Parquet/Movies/. Os metadados extra√≠dos pelo crawler foram catalogados no database filmes_trusted_db, que foi criado previamente para centralizar o cat√°logo do projeto. Dessa forma, os dados ficam organizados e acess√≠veis para consultas futuras via Athena.

![Evid√™ncia 5](../Evid√™ncias/evidencia5.png)



**Job + Crawler para TMDB**

Nessa parte, segui com o processamento dos dados da API TMDB, onde criei um job no Glue com o nome job_process_tmdb_json, utilizando a role AWSGlueServiceRole-Lab4, segui com as mesmas configura√ß√µes que j√° tinha realizado anteriormente: Glue Version 3.0, linguagem Python 3, worker type G 1x, escalonamento autom√°tico desativado, n√∫mero fixo de 2 workers, n√∫mero de tentativas como 0 e um tempo limite de execu√ß√£o de 5 minutos.

![Evid√™ncia 6](../Evid√™ncias/evidencia6.png)

Depois, fiz um script para processar os arquivos JSON da API TMDB na camada Raw do S3, definindo manualmente o schema completo dos dados para garantir que todas as estruturas complexas, como arrays e objetos aninhados, fossem corretamente interpretadas. Inicializei os contextos do Glue e Spark, e realizei a leitura dos arquivos JSON usando as op√ß√µes multiline=True e recursiveFileLookup=True para capturar todos os arquivos do diret√≥rio. Para organizar melhor a sa√≠da, extra√≠ automaticamente o ano, m√™s e dia do caminho de origem para construir dinamicamente o caminho de destino na camada Trusted. Em seguida, gravei os dados no formato Parquet, no caminho Trusted/TMDB/Parquet/Movies/{ano}/{mes}/{dia}/, utilizando o modo overwrite para garantir a atualiza√ß√£o dos dados. Finalizei o job com job.commit(). Essa abordagem garantiu a padroniza√ß√£o da estrutura dos dados e facilitou consultas futuras no Athena, evitando problemas de inconsist√™ncia e erros relacionados ao schema.

![Evid√™ncia 7](../Evid√™ncias/evidencia7.png)

![Evid√™ncia 8](../Evid√™ncias/evidencia8.png)

Para disponibilizar os dados processados da API TMDB no Glue Data Catalog, criei o crawler com o nome crawler_movies_tmdb. Configurei como fonte de dados o caminho s3 correspondente, que cont√©m os arquivos Parquet gerados a partir dos arquivos JSON da camada Raw. Utilizei a IAM Role AWSGlueServiceRole-Lab4, com as permiss√µes necess√°rias de leitura no S3 e acesso ao Glue. Apontei como destino o banco de dados filmes_trusted_db, previamente criado, permitindo que o Glue crie e atualize automaticamente a tabela conforme os dados encontrados. Ap√≥s a cria√ß√£o, executei o crawler para que a tabela correspondente fosse criada no cat√°logo e pudesse ser consultada posteriormente via AWS Athena.

![Evid√™ncia 9](../Evid√™ncias/evidencia9.png)

**Explora√ß√£o e valida√ß√£o no Athena**

Para concluir a prepara√ß√£o da camada Trusted, executei os dois crawlers previamente criados no AWS Glue: crawler_movies_csv e crawler_movies_tmdb. Ambos estavam configurados para escanear os diret√≥rios Trusted correspondentes aos dados do CSV e da API TMDB, e atualizar o cat√°logo de dados no database filmes_trusted_db. Ap√≥s a execu√ß√£o bem-sucedida, acessei o AWS Athena e confirmei a cria√ß√£o autom√°tica das tabelas csv_movies e tmdb_movies, que representam os dados j√° convertidos para o formato Parquet e prontos para consultas SQL. Com isso, finalizei a organiza√ß√£o e cataloga√ß√£o dos dados da camada Trusted, deixando o ambiente pronto para an√°lise via Athena.

![Evid√™ncia 10](../Evid√™ncias/evidencia10.png)

![Evid√™ncia 11](../Evid√™ncias/evidencia11.png)